<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="fast diffusion, machine learning, computer vision, AI">
  <!-- Project authors -->
  <meta name="author" content="Dahye Kim, Deepti Ghadiyaram, Raghudeep Gadde">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="DDiT">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to 3.52x and 3.2x speedup on FLUX-1.Dev and Wan 2.1, respectively, without compromising the generation quality and prompt adherence.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://ddit-fast.github.io/ddit/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://ddit-fast.github.io/ddit/static/images/fig1.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers">
  <meta property="og:updated_time" content="2026-02-13T12:00:00.000Z">
  <meta property="article:published_time" content="2026-01-01T12:00:00.000Z">
  <meta property="article:modified_time" content="2026-02-13T12:00:00.000Z">
  <meta property="article:author" content="Dahye Kim, Deepti Ghadiyaram, Raghudeep Gadde">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://ddit-fast.github.io/ddit/static/images/fig1.png">
  <meta name="twitter:image:alt" content="DDiT">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers">
  <meta name="citation_author" content="Kim, Dahye">
  <meta name="citation_author" content="Ghadiyaram, Deepti">
  <meta name="citation_author" content="Gadde, Raghudeep">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="arXiv">
  <meta name="citation_pdf_url" content="https://ddit-fast.github.io/ddit/static/pdfs/ddit.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/fast.png">
  <link rel="apple-touch-icon" href="static/images/fast.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "Dahye Kim",
        "affiliation": [
          {
            "@type": "Organization",
            "name": "Boston University"
          },
          {
            "@type": "Organization",
            "name": "Amazon"
          }
        ]
      },
      {
        "@type": "Person",
        "name": "Deepti Ghadiyaram",
        "affiliation": {
          "@type": "Organization",
          "name": "Boston University"
        }
      },
      {
        "@type": "Person",
        "name": "Raghudeep Gadde",
        "affiliation": {
          "@type": "Organization",
          "name": "Amazon"
        }
      }
    ],
    "datePublished": "2026-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "DDiT",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/fast.png",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>

  <!-- Google Analytics (GA4) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-B1Z8T84FMN"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-B1Z8T84FMN');
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://kim-dahye.github.io/" target="_blank" rel="noopener noreferrer">Dahye Kim</a><sup>1,2,*</sup>,
              </span>
              <span class="author-block">
                <a href="https://deeptigp.github.io/" target="_blank" rel="noopener noreferrer">Deepti Ghadiyaram</a><sup>1,&dagger;</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/raghudeep-gadde/" target="_blank" rel="noopener noreferrer">Raghudeep Gadde</a><sup>2,&dagger;</sup>
              </span>
            </div>

                  <div class="is-size-5 publication-authors affiliations-block">
                    <span class="author-block"><sup>1</sup>Boston University &nbsp; <sup>2</sup>Amazon</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Work done during internship at Amazon.</small></span>
                    <span class="eql-cntrb"><small><br><sup>&dagger;</sup>Joint last authors.</small></span>
                  </div>

                  <div class="cvpr-venue has-text-centered" style="font-size: 1.35rem; font-weight: 600;">CVPR 2026</div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://ddit-fast.github.io/ddit/static/pdfs/ddit.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                <span class="link-block">
                  <a href="https://arxiv.org/abs/2602.16968" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Figure above abstract -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/fig1.png" alt="Figure 1" loading="lazy" style="width: 100%; height: auto;" />
      <div class="content has-text-justified" style="margin-top: 1rem;">
        <p>
          <strong>DDiT dynamically selects the optimal patch size</strong> at each denoising step at inference yielding significant computational gains at no loss of perceptual quality. Results are shown for FLUX-1.Dev for text-to-image and Wan-2.1 for text-to-video generation.
          The top panel denotes the baseline (original model), while the remaining panels illustrate outputs from DDiT at different acceleration rates.
          ImageReward, CLIP, and VBench scores are reported (higher is better).
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End figure section -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose <em>dynamic tokenization</em>, an efficient <strong>test-time strategy</strong> that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to 3.52x and 3.2x speedup on FLUX-1.Dev and Wan 2.1, respectively, without compromising the generation quality and prompt adherence.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Figure 2 below abstract -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Main idea: dynamic tokenization during denoising.</h2>
    <div class="content has-text-justified" style="margin-top: 1rem;">
      <p>
        Current methods use the same patch size for <em>all</em> denoising steps during inference time. Instead, <strong>DDiT</strong> adapts the patch size at each timestep according to the latent complexity, allocating fewer tokens for certain timesteps and more tokens for certain others. While DiT divides VAE latents into patches, for illustrative purposes, we use a real image in pixel space.
      </p>
    </div>
    <div class="hero-body">
      <img src="static/images/fig2.png" alt="Figure 2" loading="lazy" style="width: 100%; height: auto;" />
    </div>
  </div>
</section>
<!-- End figure 2 section -->

<!-- Figure 3 and method details -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Dynamic Patching and Tokenization</h2>
    <div class="content has-text-justified">
      <p>
        <strong>Revised patch-embedding layer to support patches of varied resolutions.</strong> We modify the standard patch-embedding layer, designed for a fixed patch size <em>p</em>, to additionally support patch sizes <em>p</em><sub>new</sub>.
      </p>
    </div>

    <div class="hero-body" style="padding-top: 0.5rem;">
      <img src="static/images/fig3.png" alt="Figure 3" loading="lazy" style="width: 72%; height: auto; display: block; margin: 0 auto;" />
    </div>

    <h2 class="title is-3" style="margin-top: 1rem;">Dynamic Patch Scheduling</h2>
    <div class="content has-text-justified">
      <p>
        We propose a test-time <strong>Dynamic Patch Scheduler</strong> that automatically determines the optimal patch size at each timestep, adapting the computational load based on generation complexity and the input prompt. We measure the <em>rate of change of the latent manifold</em> over time. We hypothesize that this rate correlates with the level of detail being generated. If the underlying latent evolves slowly within a short timestep window, we posit that coarse-grained details are being generated. Consequently, we divide the latent into coarser patches and process them, saving computational resources. Conversely, if the underlying latent evolves rapidly, we infer that fine-grained details are being generated and fall back to using finer-grained latent patches.
      </p>
    </div>
  </div>
</section>
<!-- End figure 3 and method details -->

<!-- Results -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Results</h2>
    <div class="content has-text-justified">
      <p>
        Qualitative comparisons with the base model, TeaCache, TaylorSeer, and DDiT under similar speedups on DrawBench.
        <strong>DDiT</strong> effectively preserves fine-grained details, pose, spatial layout, and overall color distribution of the generated images.
      </p>
    </div>
    <div class="hero-body" style="padding-top: 0.5rem;">
      <img src="static/images/zoom_in.png" alt="Zoom-in qualitative comparison" loading="lazy" style="width: 72%; height: auto; display: block; margin: 0 auto;" />
    </div>

    <div class="content has-text-justified" style="margin-top: 1rem;">
      <p>
        <strong>Qualitative comparisons on PartiPrompts.</strong> The number next to the method name indicates the amount of computational speedup. Notice how for the same speedup, e.g., 2.2x, TeaCache loses the fine-grained texture in the prompt "A roast turkey." Similar observations hold true for TaylorSeer, where the overall color distribution and the background are not preserved in the prompts "A pumpkin" and "a dolphin."
      </p>
    </div>
    <div class="hero-body" style="padding-top: 0.5rem;">
      <img src="static/images/fig4.png" alt="Additional qualitative comparison" loading="lazy" style="width: 72%; height: auto; display: block; margin: 0 auto;" />
    </div>
    <div class="hero-body" style="padding-top: 0.5rem;">
      <div class="content has-text-justified" style="margin-bottom: 0.75rem;">
        <p>
          <strong>Qualitative comparison of text-to-video generation between DDiT and the baseline.</strong> DDiT produces videos with comparable visual quality to the baseline while achieving significant speedup.
        </p>
      </div>
      <video controls preload="metadata" style="width: 72%; height: auto; display: block; margin: 0 auto;">
        <source src="static/videos/Wan_vs_DDiT.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End results -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{kim2026ddit,
  title={DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers},
  author={Dahye Kim and Deepti Ghadiyaram and Raghudeep Gadde},
  journal={arXiv preprint arXiv:2602.16968},
  year={2026},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer" style="padding: 1rem 0;">
    <div class="container has-text-centered" style="font-size: 12px; color: #9ca3af; opacity: 0.75;">
      Built with the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank" rel="noopener noreferrer" style="color: #9ca3af;">Academic Project Page Template</a> (adapted from <a href="https://nerfies.github.io" target="_blank" rel="noopener noreferrer" style="color: #9ca3af;">Nerfies</a>), licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" style="color: #9ca3af;">CC BY-SA 4.0</a>.
    </div>
  </footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
